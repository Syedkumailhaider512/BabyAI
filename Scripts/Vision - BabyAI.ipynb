{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOe+C7J6aA2bb5UN1U/axDY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Vision Experiment 1**"],"metadata":{"id":"G-qT0jMboDmG"}},{"cell_type":"code","source":["# Install deps (quiet)\n","!pip -q install opencv-python-headless==4.10.0.84 pillow matplotlib gradio orjson\n","\n","import os, sys, json, math, time, threading\n","from pathlib import Path\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Make folders\n","Path(\"/content/spikes\").mkdir(parents=True, exist_ok=True)\n","Path(\"/content\").mkdir(parents=True, exist_ok=True)\n","\n","print(\"Ready. OpenCV:\", cv2.__version__)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25BE5JTim5_4","executionInfo":{"status":"ok","timestamp":1755821526933,"user_tz":-60,"elapsed":6952,"user":{"displayName":"Syed Kumail Haider","userId":"06848074158658271184"}},"outputId":"b792c676-f51f-43fe-dc36-68b803232b1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hReady. OpenCV: 4.10.0\n"]}]},{"cell_type":"code","source":["# babyai_vision_colab.py – single-file core for Colab\n","import json, time, math, threading\n","from dataclasses import dataclass, asdict\n","from pathlib import Path\n","import numpy as np\n","import cv2\n","\n","def now_iso():\n","    return time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())\n","\n","def ensure_dir(p: Path):\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","def ema_update(prototype, x, beta=0.9):\n","    return beta * prototype + (1.0 - beta) * x\n","\n","def cosine_sim(a, b, eps=1e-8):\n","    a = np.asarray(a, np.float32); b = np.asarray(b, np.float32)\n","    num = float(np.dot(a, b))\n","    den = float(np.linalg.norm(a) * np.linalg.norm(b)) + eps\n","    return num / den\n","\n","def _json_compact_dump(path: Path, data: dict):\n","    try:\n","        import orjson\n","        with open(path, \"wb\") as f:\n","            f.write(orjson.dumps(data, option=orjson.OPT_SERIALIZE_NUMPY))\n","    except Exception:\n","        with open(path, \"w\", encoding=\"utf-8\") as f:\n","            json.dump(data, f, separators=(\",\", \":\"))\n","\n","# ---------------- Retina ----------------\n","@dataclass\n","class RetinaParams:\n","    sigma_c: float = 1.5\n","    sigma_s: float = 3.5\n","    Kc: float = 1.0\n","    Ks: float = 0.8\n","    temporal_tau1: float = 8.0\n","    temporal_tau2: float = 16.0\n","    on_off_split: bool = True\n","    saccades: int = 5\n","    jitter_px: int = 2\n","    drive_gain: float = 1.0\n","    nl_alpha: float = 1.0\n","\n","def _gaussian2d_same_grid(sigma, max_sigma):\n","    k = int(3 * max_sigma)\n","    ax = np.arange(-k, k + 1, dtype=np.float32)\n","    xx, yy = np.meshgrid(ax, ax, indexing=\"xy\")\n","    g = np.exp(-(xx**2 + yy**2) / (2.0 * np.float32(sigma)**2))\n","    s = g.sum()\n","    if s > 0: g /= s\n","    return g\n","\n","def dog_kernel(params: RetinaParams):\n","    max_sigma = max(params.sigma_c, params.sigma_s)\n","    gc = _gaussian2d_same_grid(params.sigma_c, max_sigma)\n","    gs = _gaussian2d_same_grid(params.sigma_s, max_sigma)\n","    kdog = params.Kc * gc - params.Ks * gs\n","    return (kdog - kdog.mean()).astype(np.float32)\n","\n","def to_luminance(img_bgr):\n","    img = img_bgr.astype(np.float32) / 255.0\n","    b, g, r = img[...,0], img[...,1], img[...,2]\n","    return 0.299*r + 0.587*g + 0.114*b\n","\n","def microsaccades(img, n, jitter):\n","    H, W = img.shape\n","    frames = []\n","    rng = np.random.default_rng(0)\n","    for _ in range(n):\n","        dx = rng.integers(-jitter, jitter+1)\n","        dy = rng.integers(-jitter, jitter+1)\n","        M = np.float32([[1,0,dx],[0,1,dy]])\n","        warped = cv2.warpAffine(img, M, (W, H), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n","        frames.append(warped)\n","    return np.stack(frames, axis=0)\n","\n","def biphasic_temporal_filter(T, tau1, tau2):\n","    t = np.arange(T, dtype=np.float32)\n","    k = t*np.exp(-t/tau1) - 0.6*t*np.exp(-t/tau2)\n","    k = k - k.mean()\n","    norm = np.sqrt((k**2).sum()) + 1e-8\n","    return k / norm\n","\n","def retina_drive(img_bgr, params: RetinaParams):\n","    if img_bgr is None:\n","        raise ValueError(\"retina_drive: img_bgr is None\")\n","    if img_bgr.ndim == 2:\n","        img_bgr = cv2.cvtColor(img_bgr, cv2.COLOR_GRAY2BGR)\n","    Y = to_luminance(img_bgr)\n","    frames = microsaccades(Y, params.saccades, params.jitter_px)\n","    kdog = dog_kernel(params)\n","    drive = np.zeros_like(frames)\n","    for t in range(frames.shape[0]):\n","        drive[t] = cv2.filter2D(frames[t], -1, kdog, borderType=cv2.BORDER_REFLECT)\n","    ktemp = biphasic_temporal_filter(frames.shape[0], params.temporal_tau1, params.temporal_tau2)\n","    drive_t = np.tensordot(ktemp, drive, axes=(0,0)).astype(np.float32)\n","    if params.on_off_split:\n","        on = np.clip(drive_t, 0, None)\n","        off = np.clip(-drive_t, 0, None)\n","        return on, off\n","    else:\n","        return np.clip(drive_t, 0, None), None\n","\n","# --------------- V1 / spikes ---------------\n","def poisson_spikes(rate, T_ms=50, dt_ms=1.0, rng=None):\n","    if rng is None: rng = np.random.default_rng()\n","    steps = int(T_ms / dt_ms)\n","    lam = (rate / 1000.0) * dt_ms\n","    lam = np.clip(lam, 0, 1.0)\n","    spikes = rng.random((steps, rate.shape[0])) < lam[None, :]\n","    return spikes.astype(np.uint8)\n","\n","def rgc_spike_generator(on_map, off_map, gain=1.0, nl_alpha=1.0, topk=1024):\n","    def pick_topk(X):\n","        v = X.reshape(-1)\n","        k = min(topk, v.size)\n","        idx = np.argpartition(-v, k-1)[:k]\n","        idx = idx[np.argsort(-v[idx])]\n","        return idx, v[idx]\n","    on_idx, on_vals = pick_topk(on_map)\n","    off_vals_base = np.zeros_like(on_map) if off_map is None else off_map\n","    off_idx, off_vals = pick_topk(off_vals_base)\n","    v = np.concatenate([on_vals, off_vals], axis=0)\n","    rate = gain * np.maximum(0.0, np.exp(nl_alpha * (v / (v.std()+1e-6))) - 1.0)\n","    rate = np.nan_to_num(rate, nan=0.0, posinf=0.0, neginf=0.0)\n","    spikes = poisson_spikes(rate, T_ms=50, dt_ms=1.0)\n","    return spikes, rate, np.concatenate([on_idx, off_idx + on_map.size], axis=0)\n","\n","def divisive_normalization(x, pool_alpha=1.5, sigma=0.1):\n","    if x.ndim == 2:\n","        denom = sigma + cv2.GaussianBlur(np.abs(x)**pool_alpha, (0,0), 1.0)\n","        return x / denom\n","    else:\n","        denom = sigma + np.mean(np.abs(x)**pool_alpha)\n","        return x / denom\n","\n","@dataclass\n","class V1Params:\n","    orientations: int = 8\n","    scales: int = 4\n","    lam0: float = 4.0\n","    lam_mul: float = 1.8\n","    sigma_frac: float = 0.6\n","    gamma: float = 0.9\n","\n","_GABOR_CACHE = {}\n","def build_gabor_bank(H, W, vp: V1Params):\n","    key = (H, W, int(vp.orientations), int(vp.scales), float(vp.lam0), float(vp.lam_mul), float(vp.sigma_frac), float(vp.gamma))\n","    if key in _GABOR_CACHE: return _GABOR_CACHE[key]\n","    bank = []\n","    thetas = np.linspace(0, np.pi, vp.orientations, endpoint=False)\n","    lams = [vp.lam0 * (vp.lam_mul**s) for s in range(vp.scales)]\n","    for lam in lams:\n","        sigma = vp.sigma_frac * lam\n","        ksize = int(max(7, 6*sigma)) | 1\n","        for th in thetas:\n","            ge = cv2.getGaborKernel((ksize, ksize), sigma, th, lam, vp.gamma, psi=0, ktype=cv2.CV_32F)\n","            go = cv2.getGaborKernel((ksize, ksize), sigma, th, lam, vp.gamma, psi=np.pi/2, ktype=cv2.CV_32F)\n","            bank.append((ge, go))\n","    _GABOR_CACHE[key] = bank\n","    return bank\n","\n","def v1_energy_maps(img_gray, bank):\n","    energies = []\n","    for (ge, go) in bank:\n","        fe = cv2.filter2D(img_gray, -1, ge, borderType=cv2.BORDER_REFLECT)\n","        fo = cv2.filter2D(img_gray, -1, go, borderType=cv2.BORDER_REFLECT)\n","        e = np.sqrt(fe*fe + fo*fo).astype(np.float32)\n","        energies.append(e)\n","    return energies\n","\n","def spatial_pool(energies, grid=(8,8)):\n","    H, W = energies[0].shape\n","    gh, gw = grid\n","    h, w = H//gh, W//gw\n","    feats = []\n","    for e in energies:\n","        ec = e[:gh*h, :gw*w]\n","        ec = ec.reshape(gh, h, gw, w).mean(axis=(1,3))\n","        feats.append(ec.reshape(-1))\n","    return np.concatenate(feats, axis=0).astype(np.float32)\n","\n","def features_to_spikes(feat, scale=12.0):\n","    z = (feat - feat.mean()) / (feat.std() + 1e-6)\n","    rate = np.clip(np.exp(z) - 1.0, 0, None) * scale\n","    spk = poisson_spikes(rate, T_ms=50, dt_ms=1.0)\n","    return spk, rate\n","\n","# --------------- Learning / STDP ---------------\n","@dataclass\n","class LearningParams:\n","    A_plus: float = 0.02\n","    A_minus: float = -0.025\n","    tau_plus: float = 20.0\n","    tau_minus: float = 20.0\n","    decay_lambda: float = 0.9995\n","    dopamine: float = 1.0\n","\n","def stdp_update(W, pre_spk, post_spk, lp: LearningParams):\n","    T, N = pre_spk.shape\n","    if N != W.shape[0]: W = np.resize(W, (N,))\n","    if not post_spk.any():\n","        W *= lp.decay_lambda; return W\n","    post_t = np.where(post_spk)[0].mean()\n","    for n in range(N):\n","        tlist = np.where(pre_spk[:, n])[0]\n","        if tlist.size == 0: continue\n","        dt = tlist.mean() - post_t\n","        if dt < 0:\n","            dw = lp.A_plus * np.exp(dt / lp.tau_plus)\n","        else:\n","            dw = lp.A_minus * np.exp(-dt / lp.tau_minus)\n","        W[n] = max(0.0, W[n] + lp.dopamine * dw)\n","    W *= lp.decay_lambda\n","    return W\n","\n","# --------------- Auto Dopamine ---------------\n","@dataclass\n","class AutoDopaConfig:\n","    a_pos: float = 0.8\n","    a_neg: float = 0.6\n","    alpha_V: float = 0.15\n","    kappa: float = 0.1\n","    b_rho: float = 0.6\n","    b_nov: float = 0.25\n","    b_unc: float = 0.20\n","    b_fatigue: float = 0.15\n","    rho0: float = 0.5\n","    wP: float = 0.65\n","    wT: float = 0.35\n","    Dmin: float = 0.4\n","    Dmax: float = 2.0\n","    beta_softmax: float = 8.0\n","    eta_novelty: float = 0.05\n","    fatigue_rise: float = 0.10\n","    fatigue_decay_sec: float = 120.0\n","\n","class AutoDopamine:\n","    def __init__(self, meta: dict):\n","        self.cfg = AutoDopaConfig()\n","        st = meta.get(\"dopamine_state\", {})\n","        self.rhat = float(st.get(\"rhat\", 0.5))\n","        self.rho  = float(st.get(\"rho\", 0.5))\n","        self.fatigue = float(st.get(\"fatigue\", 0.0))\n","        self.last_ts = float(st.get(\"last_ts\", time.time()))\n","        meta[\"dopamine_state\"] = {\n","            \"rhat\": self.rhat, \"rho\": self.rho, \"fatigue\": self.fatigue, \"last_ts\": self.last_ts\n","        }\n","        self._meta = meta\n","\n","    def _write_back(self):\n","        self._meta[\"dopamine_state\"].update(\n","            {\"rhat\": self.rhat, \"rho\": self.rho, \"fatigue\": self.fatigue, \"last_ts\": self.last_ts}\n","        )\n","\n","    def _entropy_from_scores(self, sims, beta):\n","        if len(sims) == 0: return 0.0\n","        z = np.array(sims, dtype=np.float32)\n","        p = np.exp(beta * z - np.max(beta*z))\n","        p = p / (p.sum() + 1e-8)\n","        return float(-(p * (np.log(p + 1e-8))).sum())\n","\n","    def step(self, feat: np.ndarray, label: str, all_protos: dict) -> dict:\n","        cfg = self.cfg\n","        now = time.time(); dt = max(1e-3, now - self.last_ts)\n","\n","        sims = [cosine_sim(feat, p) for p in all_protos.values()]\n","        sims_sorted = sorted(sims, reverse=True) if sims else []\n","        max_sim = sims_sorted[0] if sims_sorted else -1.0\n","\n","        s_lab = cosine_sim(feat, all_protos[label]) if label in all_protos else -1.0\n","        s01 = (s_lab + 1.0) * 0.5\n","\n","        novelty = 1.0 - max(-1.0, min(1.0, max_sim))\n","        novelty = max(0.0, min(2.0, novelty))\n","        H = self._entropy_from_scores(sims_sorted[:8], cfg.beta_softmax)\n","\n","        r_t = float(max(0.0, min(1.0, s01 + cfg.eta_novelty * novelty)))\n","        delta = r_t - self.rhat\n","        P = 1.0 + cfg.a_pos * max(0.0, delta) - cfg.a_neg * max(0.0, -delta)\n","\n","        decay = math.exp(-dt / max(1.0, cfg.fatigue_decay_sec))\n","        self.fatigue = self.fatigue * decay + cfg.fatigue_rise * (1.0 - decay)\n","        T = 1.0 + cfg.b_rho * (self.rho - cfg.rho0) + cfg.b_nov * novelty + cfg.b_unc * H - cfg.b_fatigue * self.fatigue\n","\n","        D = float(max(cfg.Dmin, min(cfg.Dmax, cfg.wP * P + cfg.wT * T)))\n","\n","        self.rhat = (1.0 - cfg.alpha_V) * self.rhat + cfg.alpha_V * r_t\n","        self.rho  = (1.0 - cfg.kappa)   * self.rho  + cfg.kappa   * r_t\n","        self.last_ts = now\n","        self._write_back()\n","\n","        return {\"dopamine\": D, \"P\": P, \"T\": T, \"delta\": float(delta),\n","                \"r\": r_t, \"s_label\": s_lab, \"novelty\": float(novelty), \"uncertainty\": float(H),\n","                \"rhat\": self.rhat, \"rho\": self.rho, \"fatigue\": self.fatigue}\n","\n","# --------------- IT invariance ---------------\n","@dataclass\n","class ITParams:\n","    use_it: bool = True\n","    s2_rbf_sigma: float = 0.8\n","    max_exemplars_per_label: int = 12\n","    pool_mode: str = \"max\"           # \"max\" | \"median\"\n","    growth_start_deg: float = 0.0\n","    growth_max_deg: float = 60.0\n","    growth_start_scale: float = 1.0\n","    growth_max_scale: float = 1.6\n","    growth_steps: int = 5\n","    jitter_px: int = 4\n","    contrast_jit: float = 0.15\n","    ema_beta_proto: float = 0.90\n","    min_margin_target: float = 0.12\n","\n","_IT_MAX_VIEWS = 10  # set to 4 for fast training\n","\n","def _rand_contrast(img, jitter=0.15, rng=None):\n","    rng = rng or np.random.default_rng()\n","    c = 1.0 + float(rng.uniform(-jitter, jitter))\n","    out = np.clip(img * c, 0, 255).astype(img.dtype)\n","    return out\n","\n","def _affine_warp(img, angle_deg=0.0, scale=1.0, dx=0, dy=0):\n","    H, W = img.shape[:2]\n","    M = cv2.getRotationMatrix2D((W/2, H/2), angle_deg, scale); M[:,2] += (dx, dy)\n","    return cv2.warpAffine(img, M, (W, H), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n","\n","def _generate_augmented_views(img_bgr, itp: ITParams, experience_ratio: float):\n","    rot_max = itp.growth_start_deg + (itp.growth_max_deg - itp.growth_start_deg) * experience_ratio\n","    scl_max = itp.growth_start_scale + (itp.growth_max_scale - itp.growth_start_scale) * experience_ratio\n","    rng = np.random.default_rng(0)\n","\n","    views = []\n","    base = _rand_contrast(img_bgr, itp.contrast_jit, rng)\n","    views.append(base)\n","\n","    angles = [0.0, +rot_max, -rot_max/2]\n","    scales = [1.0, scl_max, max(1.0, 1.0/np.sqrt(max(1e-6, scl_max)))]\n","    shifts = [(0,0), (itp.jitter_px, 0), (0, itp.jitter_px)]\n","    for th in angles:\n","        for sc in scales:\n","            for (dx,dy) in shifts[:2]:\n","                v = _affine_warp(base, angle_deg=th, scale=sc, dx=dx, dy=dy)\n","                views.append(v)\n","    return views[:_IT_MAX_VIEWS]\n","\n","def v1_feature_from_bgr(img_bgr, ret_params: RetinaParams, v1_params: V1Params):\n","    on_map, _ = retina_drive(img_bgr, ret_params)\n","    on_lgn = divisive_normalization(on_map)\n","    bank = build_gabor_bank(on_map.shape[0], on_map.shape[1], v1_params)\n","    energies = v1_energy_maps(on_lgn, bank)\n","    feat = spatial_pool(energies, grid=(8,8))\n","    return feat\n","\n","def rbf_sim(x, c, sigma=0.8, eps=1e-8):\n","    d2 = np.sum((x - c)**2) / ( (np.linalg.norm(x)+eps)*(np.linalg.norm(c)+eps) )\n","    return float(np.exp(- d2 / (2.0 * sigma**2)))\n","\n","# --------------- Persistent Brain ---------------\n","class VisionBrain:\n","    def __init__(self, path=\"/content/brain.json\"):\n","        self.path = Path(path)\n","        self.data = {\"vision\": {}, \"crossmodal\": {}, \"meta\": {}, \"it\": {}, \"experience\": {\"n\":0}}\n","        if self.path.exists():\n","            with open(self.path, \"r\", encoding=\"utf-8\") as f:\n","                self.data = json.load(f)\n","        self.data.setdefault(\"vision\", {})\n","        self.data.setdefault(\"crossmodal\", {})\n","        self.data.setdefault(\"meta\", {})\n","        self.data.setdefault(\"it\", {})\n","        self.data.setdefault(\"experience\", {\"n\":0})\n","        self.data[\"meta\"].setdefault(\"dopamine_state\", {\"rhat\":0.5, \"rho\":0.5, \"fatigue\":0.0, \"last_ts\": time.time()})\n","\n","    def save(self):\n","        tmp = self.path.with_suffix(\".tmp.json\")\n","        _json_compact_dump(tmp, self.data)\n","        tmp.replace(self.path)\n","\n","    def save_async(self):\n","        threading.Thread(target=self.save, daemon=True).start()\n","\n","    def _ensure_label(self, label):\n","        v = self.data[\"vision\"]\n","        if label not in v:\n","            v[label] = {\"count\":0,\"updated_at\":now_iso(),\"prototype\":None,\"prototype_norm\":0.0,\n","                        \"W_sparse\":None,\"threshold_low\":0.1,\"history\":[], \"params\":{}}\n","\n","    def _all_prototypes(self):\n","        protos = {}\n","        for lab, rec in self.data[\"vision\"].items():\n","            if rec.get(\"prototype\") is not None:\n","                protos[lab] = np.array(rec[\"prototype\"], dtype=np.float32)\n","        return protos\n","\n","    def _it_experience_ratio(self, itp: ITParams):\n","        n = int(self.data.get(\"experience\", {}).get(\"n\", 0))\n","        step = max(1, itp.growth_steps)\n","        return float(min(1.0, n / (10.0 * step)))\n","\n","    def _ensure_it_label(self, label):\n","        it = self.data[\"it\"]\n","        if label not in it:\n","            it[label] = {\"exemplars\": [], \"updated_at\": now_iso()}\n","\n","    def _it_learn(self, label, img_bgr, ret_params, v1_params, itp: ITParams):\n","        self._ensure_it_label(label)\n","        it = self.data[\"it\"][label]\n","        ratio = self._it_experience_ratio(itp)\n","        views = _generate_augmented_views(img_bgr, itp, ratio)\n","        for v in views:\n","            f = v1_feature_from_bgr(v, ret_params, v1_params)\n","            it[\"exemplars\"].append({\"feat\": f.tolist()})\n","        # prune diversity set\n","        ex = [np.array(e[\"feat\"], dtype=np.float32) for e in it[\"exemplars\"]]\n","        if len(ex) > itp.max_exemplars_per_label:\n","            keep = [ex[-1]]\n","            while len(keep) < itp.max_exemplars_per_label:\n","                best_i, best_d = None, -1.0\n","                for i, vec in enumerate(ex):\n","                    dmin = min(np.linalg.norm(vec-k) for k in keep)\n","                    if dmin > best_d: best_d, best_i = dmin, i\n","                keep.append(ex[best_i])\n","            it[\"exemplars\"] = [{\"feat\": k.tolist()} for k in keep]\n","        it[\"updated_at\"] = now_iso()\n","\n","    def _it_score_label(self, label, img_bgr, ret_params, v1_params, itp: ITParams):\n","        it = self.data[\"it\"].get(label, None)\n","        if not it or not it.get(\"exemplars\"): return None\n","        ratio = self._it_experience_ratio(itp)\n","        views = _generate_augmented_views(img_bgr, itp, ratio)\n","        ex = [np.array(e[\"feat\"], dtype=np.float32) for e in it[\"exemplars\"]]\n","        sigma = itp.s2_rbf_sigma\n","        view_scores = []\n","        for v in views:\n","            f = v1_feature_from_bgr(v, ret_params, v1_params)\n","            scores = [rbf_sim(f, c, sigma) for c in ex]\n","            view_scores.append(max(scores))\n","        return float(np.median(view_scores) if itp.pool_mode==\"median\" else np.max(view_scores))\n","\n","    def record_image(self, img_bgr, label, ret_params=None, v1_params=None,\n","                     learn_params=None, store_dir=\"/content/spikes\",\n","                     auto_dopamine=False, it_params: ITParams=None, **kwargs):\n","        ret_params = ret_params or RetinaParams()\n","        v1_params  = v1_params  or V1Params()\n","        it_params  = it_params  or ITParams()\n","        learn_params = learn_params or LearningParams()\n","\n","        on_map, off_map = retina_drive(img_bgr, ret_params)\n","        rgc_spk, rgc_rate, rgc_idx = rgc_spike_generator(on_map, off_map, gain=ret_params.drive_gain, nl_alpha=ret_params.nl_alpha)\n","\n","        on_lgn = divisive_normalization(on_map)\n","        bank = build_gabor_bank(on_map.shape[0], on_map.shape[1], v1_params)\n","        energies = v1_energy_maps(on_lgn, bank)\n","        feat = spatial_pool(energies, grid=(8,8))\n","        v1_spk, v1_rate = features_to_spikes(feat)\n","\n","        try:\n","            store = Path(store_dir); ensure_dir(store)\n","            tstamp = int(time.time())\n","            np.savez_compressed(store / f\"vision_{label}_{tstamp}.npz\",\n","                                rgc_spk=rgc_spk, rgc_rate=rgc_rate, rgc_idx=rgc_idx,\n","                                v1_spk=v1_spk, v1_rate=v1_rate, feat=feat)\n","        except Exception:\n","            pass\n","\n","        self._ensure_label(label)\n","        rec = self.data[\"vision\"][label]\n","\n","        dopa_used = float(learn_params.dopamine)\n","        dopa_info = None\n","        if auto_dopamine:\n","            ad = AutoDopamine(self.data[\"meta\"])\n","            dopa_info = ad.step(feat, label, self._all_prototypes())\n","            dopa_used = float(dopa_info[\"dopamine\"])\n","\n","        if rec[\"prototype\"] is None:\n","            rec[\"prototype\"] = feat.tolist()\n","            rec[\"prototype_norm\"] = float(np.linalg.norm(feat))\n","        else:\n","            proto = np.array(rec[\"prototype\"], dtype=np.float32)\n","            proto = ema_update(proto, feat, beta=0.9)\n","            rec[\"prototype\"] = proto.tolist()\n","            rec[\"prototype_norm\"] = float(np.linalg.norm(proto))\n","\n","        label_spk = np.zeros((v1_spk.shape[0],), dtype=bool)\n","        label_spk[label_spk.size//2] = True\n","        if rec[\"W_sparse\"] is None:\n","            rec[\"W_sparse\"] = (0.01 * np.ones(v1_spk.shape[1], dtype=np.float32)).tolist()\n","        W = np.array(rec[\"W_sparse\"], dtype=np.float32)\n","        lp = LearningParams(**asdict(learn_params)); lp.dopamine = float(dopa_used)\n","        W = stdp_update(W, v1_spk, label_spk, lp)\n","        rec[\"W_sparse\"] = W.tolist()\n","\n","        if it_params.use_it:\n","            self._it_learn(label, img_bgr, ret_params, v1_params, it_params)\n","\n","        self.data[\"experience\"][\"n\"] = int(self.data[\"experience\"].get(\"n\",0)) + 1\n","\n","        try:\n","            it_scores = {}\n","            for lab in self.data[\"vision\"].keys():\n","                sc = self._it_score_label(lab, img_bgr, ret_params, v1_params, it_params)\n","                if sc is not None: it_scores[lab] = sc\n","            if it_scores:\n","                best_sc = it_scores.get(label, 0.0)\n","                second = sorted([v for k,v in it_scores.items() if k != label], reverse=True)\n","                sec_sc = second[0] if second else 0.0\n","                margin = best_sc - sec_sc\n","                if margin < it_params.min_margin_target:\n","                    self.data[\"experience\"][\"n\"] += 1\n","        except Exception:\n","            pass\n","\n","        rec[\"count\"] += 1\n","        rec[\"updated_at\"] = now_iso()\n","        hist_item = {\"t\": rec[\"updated_at\"], \"feat_norm\": float(np.linalg.norm(feat)),\n","                     \"proto_norm\": rec[\"prototype_norm\"], \"dopamine\": float(dopa_used)}\n","        if dopa_info is not None:\n","            hist_item.update({\"r\": dopa_info[\"r\"], \"delta\": dopa_info[\"delta\"], \"novelty\": dopa_info[\"novelty\"],\n","                              \"uncertainty\": dopa_info[\"uncertainty\"], \"rhat\": dopa_info[\"rhat\"],\n","                              \"rho\": dopa_info[\"rho\"], \"fatigue\": dopa_info[\"fatigue\"]})\n","        rec[\"history\"].append(hist_item); rec[\"history\"] = rec[\"history\"][-40:]\n","\n","        rec[\"params\"] = {\"retina\": asdict(ret_params), \"v1\": asdict(v1_params),\n","                         \"learn\": asdict(learn_params), \"auto_dopamine\": bool(auto_dopamine)}\n","\n","        try: self.save_async()\n","        except Exception: self.save()\n","\n","        return float(dopa_used), dopa_info\n","\n","    def recognize_image(self, img_bgr, ret_params=None, v1_params=None, it_params: ITParams=None, blend=0.6):\n","        ret_params = ret_params or RetinaParams()\n","        v1_params  = v1_params  or V1Params()\n","        it_params  = it_params  or ITParams()\n","\n","        on_map, _ = retina_drive(img_bgr, ret_params)\n","        on_lgn = divisive_normalization(on_map)\n","        bank = build_gabor_bank(on_map.shape[0], on_map.shape[1], v1_params)\n","        energies = v1_energy_maps(on_lgn, bank)\n","        feat = spatial_pool(energies, grid=(8,8))\n","\n","        v1_scores = {}\n","        for label, rec in self.data.get(\"vision\", {}).items():\n","            if rec.get(\"prototype\") is None: continue\n","            proto = np.array(rec[\"prototype\"], dtype=np.float32)\n","            v1_scores[label] = float(cosine_sim(feat, proto))\n","\n","        it_scores = {}\n","        if it_params.use_it:\n","            for label in self.data.get(\"vision\", {}).keys():\n","                sc = self._it_score_label(label, img_bgr, ret_params, v1_params, it_params)\n","                if sc is not None: it_scores[label] = sc\n","\n","        labels = set(v1_scores.keys()) | set(it_scores.keys())\n","        final = []\n","        for lab in labels:\n","            v1s = v1_scores.get(lab, -1.0); v1u = (v1s + 1.0) * 0.5\n","            its = it_scores.get(lab, 0.0)\n","            score01 = (1.0 - blend) * v1u + blend * its\n","            final.append((lab, score01))\n","        final.sort(key=lambda x: -x[1])\n","        return final[:5], feat\n","\n","# Helpers for plotting in Colab\n","def simulate_spikes_for_image(img_bgr, ret_params: RetinaParams, v1_params: V1Params):\n","    on_map, off_map = retina_drive(img_bgr, ret_params)\n","    rgc_spk, rgc_rate, rgc_idx = rgc_spike_generator(on_map, off_map, gain=ret_params.drive_gain, nl_alpha=ret_params.nl_alpha, topk=min(1024, on_map.size//2))\n","    on_lgn = divisive_normalization(on_map)\n","    bank = build_gabor_bank(on_map.shape[0], on_map.shape[1], v1_params)\n","    energies = v1_energy_maps(on_lgn, bank)\n","    feat = spatial_pool(energies, grid=(8,8))\n","    v1_spk, v1_rate = features_to_spikes(feat)\n","    return rgc_spk, v1_spk, energies, on_map\n"],"metadata":{"id":"m4e5WCzEm6-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def normalize01(x, eps=1e-8):\n","    x = x.astype(np.float32)\n","    mn, mx = x.min(), x.max()\n","    if mx - mn < eps: return np.zeros_like(x)\n","    return (x - mn) / (mx - mn + eps)\n","\n","def heat_overlay(base_bgr, heat, alpha=0.5, colormap=cv2.COLORMAP_TURBO):\n","    H, W = base_bgr.shape[:2]\n","    if heat.shape[:2] != (H, W):\n","        heat = cv2.resize(heat, (W, H), interpolation=cv2.INTER_LINEAR)\n","    heat8 = (normalize01(heat) * 255).astype(np.uint8)\n","    cmap = cv2.applyColorMap(heat8, colormap)\n","    return cv2.addWeighted(base_bgr, 1.0 - alpha, cmap, alpha, 0.0)\n","\n","def draw_orientation_strokes(base_bgr, energies, grid=(16,16), scale_len=14, thickness=2):\n","    H, W = base_bgr.shape[:2]\n","    gh, gw = grid\n","    cell_h, cell_w = H // gh, W // gw\n","    L = len(energies)\n","    for guess in (8,12,6,4):\n","        if L % guess == 0:\n","            orientations, scales = guess, L // guess\n","            break\n","    else:\n","        orientations, scales = L, 1\n","    Eo = []\n","    for o in range(orientations):\n","        stack = []\n","        for s in range(scales):\n","            idx = s * orientations + o\n","            stack.append(energies[idx])\n","        Eo.append(np.sum(stack, axis=0))\n","    Esum = np.sum(Eo, axis=0) + 1e-6\n","    out = base_bgr.copy()\n","    angles = np.linspace(0, np.pi, orientations, endpoint=False)\n","    for gy in range(gh):\n","        for gx in range(gw):\n","            y0, x0 = gy*cell_h, gx*cell_w\n","            y1, x1 = min((gy+1)*cell_h, H), min((gx+1)*cell_w, W)\n","            cell_vals = [E[y0:y1, x0:x1].mean() for E in Eo]\n","            cell_sum = Esum[y0:y1, x0:x1].mean()\n","            if cell_sum <= 0: continue\n","            o_idx = int(np.argmax(cell_vals))\n","            strength = float(cell_vals[o_idx] / (cell_sum + 1e-6))\n","            if strength < 0.02: continue\n","            theta = angles[o_idx]\n","            cx, cy = (x0+x1)//2, (y0+y1)//2\n","            Lstroke = int(2 + scale_len * strength**0.5)\n","            dx, dy = int(np.cos(theta)*Lstroke), int(np.sin(theta)*Lstroke)\n","            hue = int(180 * (theta / np.pi))\n","            color = tuple(int(c) for c in cv2.cvtColor(np.uint8([[[hue,200,255]]]), cv2.COLOR_HSV2BGR)[0,0])\n","            cv2.line(out, (cx - dx, cy - dy), (cx + dx, cy + dy), color, thickness, lineType=cv2.LINE_AA)\n","    return out\n","\n","def make_feature_previews(img_bgr, ret_params, v1_params):\n","    on_map, _ = retina_drive(img_bgr, ret_params)\n","    on_lgn = divisive_normalization(on_map)\n","    bank = build_gabor_bank(on_map.shape[0], on_map.shape[1], v1_params)\n","    energies = v1_energy_maps(on_lgn, bank)\n","    base_vis = cv2.cvtColor(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY), cv2.COLOR_GRAY2BGR)\n","\n","    retina_overlay = heat_overlay(base_vis, on_map, alpha=0.55, colormap=cv2.COLORMAP_PLASMA)\n","    v1_sum = np.zeros_like(energies[0], dtype=np.float32)\n","    for e in energies: v1_sum += e.astype(np.float32)\n","    v1_overlay = heat_overlay(base_vis, v1_sum, alpha=0.55, colormap=cv2.COLORMAP_TURBO)\n","    orient_vis = draw_orientation_strokes(base_vis, energies, grid=(16,16), scale_len=14, thickness=2)\n","    return retina_overlay, v1_overlay, orient_vis\n","\n","def spike_raster(ax, spikes, title):\n","    T, N = spikes.shape\n","    ys, xs = np.where(spikes > 0)\n","    ax.scatter(xs, ys, s=2, marker='|')\n","    ax.set_xlim(0, N); ax.set_ylim(T, 0)\n","    ax.set_xlabel(\"Neuron index\"); ax.set_ylabel(\"Time (step)\")\n","    ax.set_title(title)\n","\n","def plot_neuron_graphs(img_bgr, ret_params, v1_params):\n","    rgc_spk, v1_spk, energies, on_map = simulate_spikes_for_image(img_bgr, ret_params, v1_params)\n","    fig = plt.figure(figsize=(13,8))\n","    ax1 = fig.add_subplot(2,2,1); spike_raster(ax1, rgc_spk, \"RGC spike raster\")\n","    ax2 = fig.add_subplot(2,2,2); spike_raster(ax2, v1_spk, \"V1 spike raster\")\n","    # small multiples for first 8 channels\n","    for i in range(min(8, len(energies))):\n","        ax = fig.add_subplot(2,4,i+1) if i<4 else fig.add_subplot(2,4,i+1)\n","    plt.tight_layout()\n","    return rgc_spk, v1_spk, energies, on_map\n"],"metadata":{"id":"apaSYy_xoTks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== Robust image input loaders for Gradio (Colab) ====\n","import numpy as np, cv2\n","\n","def _unwrap_gallery_item(item):\n","    \"\"\"\n","    Gradio Gallery may return:\n","      - PIL.Image.Image\n","      - numpy.ndarray\n","      - (image, caption) tuple\n","      - dict with 'image'/'data'/'orig'/'value' keys\n","    Normalize to a bare PIL.Image or numpy array.\n","    \"\"\"\n","    # Tuple: (image, caption/metadata)\n","    if isinstance(item, tuple) and len(item) > 0:\n","        item = item[0]\n","\n","    # Dict: try common keys\n","    if isinstance(item, dict):\n","        for k in (\"image\", \"data\", \"orig\", \"value\"):\n","            if k in item and item[k] is not None:\n","                item = item[k]\n","                break\n","\n","    return item\n","\n","def np_from_input(image_like):\n","    \"\"\"\n","    Convert various Gradio inputs (PIL / np / tuple / dict / file-like) into OpenCV BGR ndarray.\n","    \"\"\"\n","    if image_like is None:\n","        return None\n","\n","    item = _unwrap_gallery_item(image_like)\n","\n","    # PIL.Image\n","    try:\n","        from PIL import Image\n","        if isinstance(item, Image.Image):\n","            arr = np.array(item.convert(\"RGB\"))\n","            return arr[:, :, ::-1]  # RGB->BGR\n","    except Exception:\n","        pass\n","\n","    # numpy array (H,W,3) RGB or BGR, or (H,W) gray\n","    if isinstance(item, np.ndarray):\n","        arr = item\n","        if arr.ndim == 2:\n","            arr = cv2.cvtColor(arr, cv2.COLOR_GRAY2BGR)\n","        elif arr.ndim == 3 and arr.shape[2] == 3:\n","            # Heuristic: assume RGB from Gradio and flip to BGR\n","            arr = arr[:, :, ::-1]\n","        return arr\n","\n","    # file-like (bytes)\n","    if hasattr(item, \"read\"):\n","        try:\n","            data = item.read()\n","            buf = np.frombuffer(data, dtype=np.uint8)\n","            img = cv2.imdecode(buf, cv2.IMREAD_COLOR)\n","            return img\n","        except Exception:\n","            return None\n","\n","    # Couldn’t parse\n","    return None\n"],"metadata":{"id":"lh6qFM9erx3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== Gradio UI (Record / Recognize + previews + table) ====\n","import gradio as gr\n","\n","BRAIN_PATH = \"/content/brain.json\"\n","brain = VisionBrain(BRAIN_PATH)\n","\n","def learn_images(label, auto_dopa, use_it, sigma_c, sigma_s, saccades, jitter, orients, scales, images):\n","    if not label or images is None or len(images) == 0:\n","        return \"Provide a label and at least one image.\", None, None, None, \"—\"\n","\n","    ret = RetinaParams(sigma_c=float(sigma_c), sigma_s=float(sigma_s), saccades=int(saccades), jitter_px=int(jitter))\n","    v1  = V1Params(orientations=int(orients), scales=int(scales))\n","    itp = ITParams(use_it=bool(use_it))\n","    learn = LearningParams(dopamine=1.2)\n","\n","    last = None\n","    D_used_last = None\n","    ok, fail = 0, 0\n","\n","    # images can be PIL / np / tuple / dict — robust loader handles all.\n","    for item in images:\n","        img_bgr = np_from_input(item)\n","        if img_bgr is None:\n","            fail += 1\n","            continue\n","        try:\n","            D_used, _ = brain.record_image(\n","                img_bgr=img_bgr, label=label, ret_params=ret, v1_params=v1,\n","                learn_params=learn, store_dir=\"/content/spikes\",\n","                auto_dopamine=bool(auto_dopa), it_params=itp\n","            )\n","            D_used_last = D_used; ok += 1; last = img_bgr\n","        except Exception as e:\n","            fail += 1\n","\n","    retina_viz = v1_viz = orient_viz = None\n","    if last is not None:\n","        r, v, o = make_feature_previews(last, ret, v1)\n","        retina_viz = cv2.cvtColor(r, cv2.COLOR_BGR2RGB)\n","        v1_viz = cv2.cvtColor(v, cv2.COLOR_BGR2RGB)\n","        orient_viz = cv2.cvtColor(o, cv2.COLOR_BGR2RGB)\n","\n","    dopa_text = f\"{D_used_last:.3f}\" if D_used_last is not None else \"—\"\n","    return f\"Learned {ok} image(s), failed {fail}.\", retina_viz, v1_viz, orient_viz, dopa_text\n","\n","def recognize_image(use_it, blend, sigma_c, sigma_s, saccades, jitter, orients, scales, image):\n","    if image is None:\n","        return \"Upload an image first.\", None, None, None, []\n","\n","    ret = RetinaParams(sigma_c=float(sigma_c), sigma_s=float(sigma_s), saccades=int(saccades), jitter_px=int(jitter))\n","    v1  = V1Params(orientations=int(orients), scales=int(scales))\n","    itp = ITParams(use_it=bool(use_it))\n","\n","    img_bgr = np_from_input(image)\n","    if img_bgr is None:\n","        return \"Invalid image input.\", None, None, None, [[\"—\",\"Bad input\"]]\n","\n","    top5, feat = brain.recognize_image(img_bgr, ret_params=ret, v1_params=v1, it_params=itp, blend=float(blend))\n","    r, v, o = make_feature_previews(img_bgr, ret, v1)\n","    retina_viz = cv2.cvtColor(r, cv2.COLOR_BGR2RGB)\n","    v1_viz = cv2.cvtColor(v, cv2.COLOR_BGR2RGB)\n","    orient_viz = cv2.cvtColor(o, cv2.COLOR_BGR2RGB)\n","\n","    table = [[lab, float(f\"{sc:.3f}\")] for lab, sc in top5] if top5 else [[\"—\",\"No prototypes\"]]\n","    return f\"Done. Best: {top5[0][0]} ({top5[0][1]:.3f})\" if top5 else \"No match.\", retina_viz, v1_viz, orient_viz, table\n","\n","with gr.Blocks(title=\"BabyAI Vision — Colab\") as demo:\n","    gr.Markdown(\"## BabyAI Vision — Retina→V1→IT with Auto-Dopamine (Colab)\")\n","    with gr.Tabs():\n","        with gr.Tab(\"Record (Learn)\"):\n","            with gr.Row():\n","                with gr.Column(scale=2):\n","                    label = gr.Textbox(label=\"Label\", value=\"eman\")\n","                    # Gallery can emit tuples/dicts; np_from_input handles it.\n","                    images = gr.Gallery(label=\"Training Images\", show_label=True,\n","                                        columns=3, height=240, allow_preview=True, type=\"pil\")\n","                    learn_btn = gr.Button(\"Learn Images\", variant=\"primary\")\n","                    status = gr.Markdown(\"Status: Ready\")\n","                with gr.Column(scale=1):\n","                    auto_dopa = gr.Checkbox(label=\"Auto Dopamine\", value=True)\n","                    use_it = gr.Checkbox(label=\"Use IT invariance\", value=True)\n","                    sigma_c = gr.Slider(0.5, 4.0, value=1.5, step=0.1, label=\"Retina sigma_c\")\n","                    sigma_s = gr.Slider(0.5, 8.0, value=3.5, step=0.1, label=\"Retina sigma_s\")\n","                    saccades = gr.Slider(1, 8, value=5, step=1, label=\"Microsaccades\")\n","                    jitter = gr.Slider(0, 6, value=2, step=1, label=\"Jitter (px)\")\n","                    orients = gr.Slider(4, 16, value=8, step=1, label=\"V1 orientations\")\n","                    scales = gr.Slider(1, 6, value=4, step=1, label=\"V1 scales\")\n","            with gr.Row():\n","                retina_img = gr.Image(label=\"Retina (DoG heat overlay)\", interactive=False)\n","                v1_img = gr.Image(label=\"V1 Energy heat overlay\", interactive=False)\n","                orient_img = gr.Image(label=\"V1 Orientation map\", interactive=False)\n","            dopa_used = gr.Textbox(label=\"Dopamine used (last)\", value=\"—\")\n","            learn_btn.click(\n","                fn=learn_images,\n","                inputs=[label, auto_dopa, use_it, sigma_c, sigma_s, saccades, jitter, orients, scales, images],\n","                outputs=[status, retina_img, v1_img, orient_img, dopa_used],\n","            )\n","\n","        with gr.Tab(\"Recognize\"):\n","            with gr.Row():\n","                with gr.Column(scale=2):\n","                    image = gr.Image(label=\"Query Image\", type=\"pil\")\n","                    rec_btn = gr.Button(\"Recognize\", variant=\"primary\")\n","                    rec_status = gr.Markdown(\"Status: Ready\")\n","                with gr.Column(scale=1):\n","                    use_it2 = gr.Checkbox(label=\"Use IT invariance\", value=True)\n","                    blend = gr.Slider(0.0, 1.0, value=0.6, step=0.05, label=\"Blend (0=V1, 1=IT)\")\n","                    sigma_c2 = gr.Slider(0.5, 4.0, value=1.5, step=0.1, label=\"Retina sigma_c\")\n","                    sigma_s2 = gr.Slider(0.5, 8.0, value=3.5, step=0.1, label=\"Retina sigma_s\")\n","                    saccades2 = gr.Slider(1, 8, value=5, step=1, label=\"Microsaccades\")\n","                    jitter2 = gr.Slider(0, 6, value=2, step=1, label=\"Jitter (px)\")\n","                    orients2 = gr.Slider(4, 16, value=8, step=1, label=\"V1 orientations\")\n","                    scales2 = gr.Slider(1, 6, value=4, step=1, label=\"V1 scales\")\n","            with gr.Row():\n","                retina_img2 = gr.Image(label=\"Retina (DoG heat overlay)\", interactive=False)\n","                v1_img2 = gr.Image(label=\"V1 Energy heat overlay\", interactive=False)\n","                orient_img2 = gr.Image(label=\"V1 Orientation map\", interactive=False)\n","            table = gr.Dataframe(headers=[\"Label\",\"Score\"], row_count=5)\n","\n","            rec_btn.click(\n","                fn=recognize_image,\n","                inputs=[use_it2, blend, sigma_c2, sigma_s2, saccades2, jitter2, orients2, scales2, image],\n","                outputs=[rec_status, retina_img2, v1_img2, orient_img2, table],\n","            )\n","\n","demo.launch(debug=False, share=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"ENAYyfVooXd8","executionInfo":{"status":"ok","timestamp":1755821551022,"user_tz":-60,"elapsed":3729,"user":{"displayName":"Syed Kumail Haider","userId":"06848074158658271184"}},"outputId":"3b03071b-db32-4b99-d02c-8b49c6bb16d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","* To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7860, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]}]}